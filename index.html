<!DOCTYPE html>
<html lang="en">
<head>

  <meta charset="utf-8">
  <title>xemantic</title>

  <meta name="description"  content="Kazik Pogoda, creative technologist based in Berlin, producing interactive media art installations, generative design and robots" />
  <meta name="keywords"     content="creative technologist, creative coding, code, coding, programmer, programming, software, IT, software architect, backend, frontend, web, java, kotlin, GLSL, OPENRNDR, art, installations, kinect, new media, media art, digital art, generative, generative art generative design, motion design" />
  <meta name="author"       content="Kazik Pogoda" />

  <meta property="og:title"         content="xemantic" />
  <meta property="og:type"          content="website" />
  <meta property="og:url"           content="https://xemantic.com/" />
  <meta property="og:image"         content="https://xemantic.com/logo/xemantic-avatar.png" />
  <meta property="og:image:type"    content="image/png" />
  <meta property="og:image:width"   content="400" />
  <meta property="og:image:height"  content="400" />
  <meta property="og:image:alt"     content="xemantic logo" />
  <meta property="og:description"   content="Kazik Pogoda, creative technologist based in Berlin, producing interactive media art installations, generative design and robots" />
  <meta property="og:locale"        content="en_US" />

  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="shortcut icon" href="favicon.ico">
  <link rel="apple-touch-icon" href="icons/apple-touch-icon.png">
  <link rel="apple-touch-icon" sizes="72x72" href="icons/apple-touch-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="114x114" href="icons/apple-touch-icon-114x114.png">

  <!-- don't touch this -->
  <script>
    const scriptsToLoad = []; const cssToLoad = []; const scriptsToPostLoad = [];
    function addScript(src, extender) { scriptsToLoad.push([src, extender]); }
    function addPostLoadScript(src, extender) { scriptsToPostLoad.push([src, extender]); }
    function addCss(src) { cssToLoad.push(src); }
  </script>
  <script>
    const fuckTheAiConfig = {
      useVimeo: true
    };
    addScript("custom.js");
    addScript("https://kit.fontawesome.com/0bbdfd8b39.js", (script) => {
      script.setAttribute("crossorigin", "anonymous");
    });
    addCss("https://fonts.googleapis.com/css2?family=Arsenal:ital,wght@0,400;0,700;1,400;1,700&display=swap");
    // addPostLoadScript("analytics.js");

    /* shadow settings, too much blur will make it super slow */
    const MAX_SHADOW_DROP = 5.0;
    const MAX_BLUR_RADIUS = .9;
  </script>
  <style>
    :root {
      --logo-fade-in-duration: 9s;
      --content-font-family: "Arsenal", sans-serif;

      --golden-ratio-width-longer: 61.8vw;
      --golden-ratio-width-shorter: 38.2vw;
      --golden-ratio-height-longer: 61.8vh;
      --golden-ratio-height-shorter: 38.2vh;

      /* initially background is covering everything */
      --z-index-logo: 4;
      --z-index-background: 3;
    }
    html {
      box-sizing: border-box;
      background: black;
    }
    body {
      /* prevents from future resizing of the background canvas and from flickering when
       content appears
       */
      overflow-x: hidden;
      overflow-y: scroll;
    }
    *, *:before, *:after {
      box-sizing: inherit;
    }
    body, h1, h2, h3, h4, h5, h6, p, ol, ul, blockquote, dl, dt, dd {
      margin: 0;
      padding: 0;
    }
    header {
      height: var(--golden-ratio-height-longer);
      display: flex;
      align-items: center;
      justify-content: center;
    }
    header .logo {
      width: var(--golden-ratio-width-longer);
      opacity: 0;
      animation: fade-in var(--logo-fade-in-duration) ease-in-out;
      animation-fill-mode: forwards; /* will keep the opacity */
      z-index: var(--z-index-logo);
    }
    @keyframes fade-in {
      from { opacity: 0; }
      to   { opacity: 1; }
    }
    #shader-background {
      background: var(--background); /* covers everything */
      position: fixed;
      top: 0;
      left: 0;
      width: 100vw;
      height: 100vh;
      z-index: var(--z-index-background-layer);
    }
    #shader-background.fallback {
      background: var(--background-shader-fallback);
      background-repeat: no-repeat;
      background-position: center top;
      background-size: cover;
    }
    .hidden {
      display: none;
    }

    /* moving shadow: start (optional) */
    :root {
      /* initial shadow values - later on supplied from mouse or touch events */
      --shadow-x: 1.3vw;
      --shadow-y: 1.3vw;
      --shadow-blur-radius: .15vw;
      --shadow-opacity: .8;
    }
    .shadow {
      filter: drop-shadow(var(--shadow-x) var(--shadow-y) var(--shadow-blur-radius) rgba(0, 0, 0, var(--shadow-opacity)));
    }
    /* moving shadow: end */

    /* should be in the library */
    ul {
      padding-left: 1.68rem;
    }
    h3 {
      font-style: italic;
      font-size: 1rem;
      margin-bottom: 1rem;
    }
    dl {
      display: grid;
      grid-gap: 1rem;
      margin-bottom: 1rem;
    }
    dt {
      grid-column-start: 1;
      text-align: right;
    }
    dd {
      grid-column-start: 2;
      font-style: italic;
    }
  </style>
  <script>
    const MAIN_JS = "https://xemantic.github.io/fuck-the-ai-which-is-abusing-your-reptilian-brain-to-make-you-addicted-to-movies-instead-of-art/main.js";
    addCss("https://xemantic.github.io/fuck-the-ai-which-is-abusing-your-reptilian-brain-to-make-you-addicted-to-movies-instead-of-art/main.css");

    const root = document.documentElement;

    function handleMove(event) {
      const x = (event.clientX - .5 * innerWidth) / innerWidth;
      const y = (event.clientY - .5 * innerHeight) / innerWidth;
      const distance = Math.sqrt((x * x) + (y * y));
      root.style.setProperty("--shadow-x", (x * -MAX_SHADOW_DROP) + "vw");
      root.style.setProperty("--shadow-y", (y * -MAX_SHADOW_DROP) + "vw");
      root.style.setProperty("--shadow-blur-radius", ((distance * MAX_BLUR_RADIUS) + "vw"));
    }
    document.addEventListener("mousemove", handleMove, false);
    document.addEventListener("touchmove", handleMove, false);

    // now we have to fix chrome native image lazy loading which is still trying to download some
    // images before the page emits load event
    const supportsLazyLoad = ("loading" in document.createElement("img"));
    const lazyLoadingProcessor = (supportsLazyLoad && window.MutationObserver) ? new MutationObserver(mutations => {
      mutations.forEach(mutation => {
        mutation.addedNodes.forEach(node => {
          if (node.nodeName == "IMG" && node.loading && (node.loading == "lazy")) {
            node.setAttribute("data-src", node.src);
            node.src = "";
          }
        });
      });
    }) : null;

    window.addEventListener("load", e => {
      if (lazyLoadingProcessor) {
        lazyLoadingProcessor.disconnect();
      }

      try {
        shaderCanvas("shader-background", "feedback-shader");
      } catch (e) {
        const shaderBackground = document.getElementById("shader-background");
        shaderBackground.classList.add("fallback");
      }

      const script = document.createElement("script");
      script.src = MAIN_JS;
      script.async = true;
      document.head.appendChild(script);
    }, false);

    // shaderCanvas: start
    function m(a){var c=0;return function(){return c<a.length?{done:!1,value:a[c++]}:{done:!0}}}function r(a){return Error(a)}r.prototype=Object.create(Error.prototype);
    function u(a,c,e){function f(){t=performance.now()/1E3;if(d.width!==d.clientWidth||d.height!==d.clientHeight){d.width=d.clientWidth;d.height=d.clientHeight;b.viewport(0,0,b.canvas.width,b.canvas.height);var g=k;var l="undefined"!=typeof Symbol&&Symbol.iterator&&g[Symbol.iterator];g=l?l.call(g):{next:m(g)};for(l=g.next();!l.done;l=g.next())l.value.release();k=w(b,d.width,d.height,q);p()}b.useProgram(h);b.uniform1f(A,t);b.uniform1i(B,v);b.bindFramebuffer(b.FRAMEBUFFER,k[0].c);b.bindTexture(b.TEXTURE_2D,
    k[1].b);b.drawArrays(b.TRIANGLE_STRIP,0,4);b.useProgram(n);b.bindFramebuffer(b.FRAMEBUFFER,null);b.bindTexture(b.TEXTURE_2D,k[0].b);b.drawArrays(b.TRIANGLE_STRIP,0,4);k.reverse();v++;requestAnimationFrame(f)}function p(){var g=Math.min(d.width,d.height);b.useProgram(h);b.uniform2f(C,d.width,d.height);b.uniform1f(D,g);b.useProgram(n);b.uniform2f(E,d.width,d.height);b.uniform1f(F,g)}var d=document.getElementById(a);d.width=d.clientWidth;d.height=d.clientHeight;var b=d.getContext("webgl");if(!b)throw new r("webgl context not supported on supplied canvas element: "+
    d);var q=b.getExtension("OES_texture_half_float");if(!q)throw new r("OES_texture_half_float is required but not supported here");if(!b.getExtension("OES_texture_half_float_linear"))throw new r("OES_texture_half_float_linear is required but not supported here");var k=w(b,d.width,d.height,q),h=x(b,c),n=x(b,e);b.useProgram(h);a=b.getAttribLocation(h,"V");c=y(b);b.bindBuffer(b.ARRAY_BUFFER,c);b.vertexAttribPointer(a,2,b.FLOAT,!1,0,0);b.enableVertexAttribArray(a);b.viewport(0,0,b.canvas.width,b.canvas.height);
    var C=b.getUniformLocation(h,"R"),D=b.getUniformLocation(h,"D"),A=b.getUniformLocation(h,"T"),B=b.getUniformLocation(h,"F");b.useProgram(n);var E=b.getUniformLocation(n,"R"),F=b.getUniformLocation(n,"D");p();var v=0,t=0;f()}
    function z(a,c,e,f){this.a=a;this.b=a.createTexture();a.bindTexture(a.TEXTURE_2D,this.b);a.texImage2D(a.TEXTURE_2D,0,a.RGBA,c,e,0,a.RGBA,f.HALF_FLOAT_OES,null);a.texParameteri(a.TEXTURE_2D,a.TEXTURE_MIN_FILTER,a.LINEAR);a.texParameteri(a.TEXTURE_2D,a.TEXTURE_MAG_FILTER,a.LINEAR);a.texParameteri(a.TEXTURE_2D,a.TEXTURE_WRAP_S,a.CLAMP_TO_EDGE);a.texParameteri(a.TEXTURE_2D,a.TEXTURE_WRAP_T,a.CLAMP_TO_EDGE);this.c=a.createFramebuffer();a.bindFramebuffer(a.FRAMEBUFFER,this.c);a.framebufferTexture2D(a.FRAMEBUFFER,
    a.COLOR_ATTACHMENT0,a.TEXTURE_2D,this.b,0)}z.prototype.release=function(){this.a.bindFramebuffer(this.a.FRAMEBUFFER,this.c);this.a.deleteTexture(this.b);this.a.bindFramebuffer(this.a.FRAMEBUFFER,null);this.a.deleteFramebuffer(this.c)};function G(a,c,e){c=a.createShader(c);a.shaderSource(c,e);a.compileShader(c);if(!a.getShaderParameter(c,a.COMPILE_STATUS)){var f=String(a.getShaderInfoLog(c));console.log(f,e);a.deleteShader(c);return f}return c}
    function x(a,c){var e=G(a,a.VERTEX_SHADER,"\nattribute vec2 V;\n//attribute vec2 aUV;\n//varying vec2 vUV;\n\nvoid main() {\n    gl_Position = vec4(V, 0.0, 1.0);\n    //vUV = aUV;\n}\n");c=G(a,a.FRAGMENT_SHADER,c);var f=a.createProgram();a.attachShader(f,e);a.attachShader(f,c);a.linkProgram(f);return f}function y(a){var c=a.createBuffer();a.bindBuffer(a.ARRAY_BUFFER,c);a.bufferData(a.ARRAY_BUFFER,new Float32Array([-1,1,1,1,-1,-1,1,-1]),a.STATIC_DRAW);return c}
    function w(a,c,e,f){var p=new z(a,c,e,f);a=new z(a,c,e,f);return[p,a]}
    window.shaderCanvas=function(a,c,e){return new u(a,c&&document.getElementById(c)&&document.getElementById(c).text.trim()||"\nprecision mediump float;\n\nuniform vec2 R;\nuniform sampler2D T;\nvarying vec2 vUV;\n\nvoid main() {\n    // vUV is equal to gl_FragCoord/uScreenResolution\n    // do some pixel shader related work\n    gl_FragColor = vec4(0.);\n}\n",e&&document.getElementById(e)&&document.getElementById(e).text.trim()||"\nprecision mediump float;\n\nuniform vec2 R;\nuniform sampler2D T;\nvarying vec2 vUV;\n\nvoid main() {\n    // vUV is equal to gl_FragCoord/uScreenResolution\n    // do some pixel shader related work\n    gl_FragColor = texture2D(T, gl_FragCoord.xy/R);\n}\n")};
    window.WebglLoopbackException=r;
    // shaderCanvas: end
  </script>
  <script type="x-shader/x-fragment" id="feedback-shader">
    precision lowp float; precision lowp int; precision lowp sampler2D; uniform vec2 R;uniform float D,T;
    uniform sampler2D T0;void main(){lowp vec3 v;highp vec2 f;f=gl_FragCoord.xy/R;
    highp vec2 m;m=(gl_FragCoord.xy*2.-R)/D;highp vec2 h;h=f-m/R*20.7;lowp vec2 i;i=(texture2D(T0,h).xy-vec2(.3,.3))*vec2(.002,.002);
    highp vec2 l;l=f-i;v=texture2D(T0,l).xyz*.999;highp float u;u=sqrt(dot(m,m));if(u<.618){highp float e,c;
    c=clamp((u-.618)/-.016,0.,1.);e=c*(c*(3.-2.*c))*(u/.618);highp float p;p=pow(e,20.);e=p;float o;
    o=float(mod(T*.1,1.));vec3 y;y=vec3(3.54585,2.93225,2.41594)*(o-vec3(.695491,.492283,.276999));
    vec3 z;z=vec3(3.90307,3.21183,3.96587)*(o-vec3(.117486,.86755,.660779));
    v=v+(min(max(vec3(1.,1.,1.)-y*y-vec3(.0231264,.152251,.52608),0.),1.)+
    min(max(vec3(1.,1.,1.)-z*z-vec3(.848971,.884453,.739495),0.),1.))*p*.03;if(u<.4944){highp float t;
    t=clamp((u-.4944)/-.016,0.,1.);e=t*(t*(3.-2.*t))*(u/.4944);highp float s;s=pow(e,20.);e=s;float g;
    g=float(mod(T*.1+.5,1.));vec3 w;w=vec3(3.54585,2.93225,2.41594)*(g-vec3(.695491,.492283,.276999));
    vec3 a;a=vec3(3.90307,3.21183,3.96587)*(g-vec3(.117486,.86755,.660779));v=v+(min(max(vec3(1.,1.,1.)-
    w*w-vec3(.0231264,.152251,.52608),0.),1.)+min(max(vec3(1.,1.,1.)-a*a-vec3(.848971,.884453,.739495),0.),1.))*s*.03;}
    v=clamp(v,0.,1.);}lowp vec4 p;p.w=1.;p.xyz=v;gl_FragColor=p;}
  </script>
</head>
<body>
<script>
  // installing the processor as early as possible, after the body is created
  if (lazyLoadingProcessor) {
    lazyLoadingProcessor.observe(document.body, {childList: true, subtree: true});
  }
</script>
<header>
  <svg class="logo shadow" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1052.5 212">
    <defs/>
    <path fill="#fff" fill-rule="evenodd" d="M997.632 179.087c-41.02 0-63.905-30.14-63.905-69.283s22.886-69.283 63.905-69.283c30.39 0 51.9 17.883 54.651 46.647h-25.262c-2.376-14.632-13.006-25.262-28.013-25.262h-2.626c-25.262 0-37.268 22.636-37.268 48.023s12.006 48.023 37.268 48.023h2.626c14.882 0 25.637-10.63 28.013-25.262h25.262c-2.626 28.639-24.261 46.397-54.65 46.397zM885.829 27.265h25.262V176.46h-25.262zm-76.787 101.798V65.158h-29.264V43.272h29.264V.127h25.262v43.145h32.015v21.886h-32.015v118.557c0 18.634-9.38 28.013-28.014 28.013h-20.01v-22.636h12.007c8.003 0 10.63-2.626 10.63-10.63v-49.399zm-135.94-27.138v74.661h-25.263V27.265h25.263v34.641c8.003-12.006 21.26-21.26 42.645-21.26 30.64 0 48.023 18.634 48.023 46.647v89.293h-25.262V92.671c0-18.634-8.004-30.64-26.638-30.64h-2.626c-18.76-.125-36.142 14.507-36.142 39.894zm-288.139 21.261v25.262c0 18.634-9.38 28.013-28.013 28.013h-20.01v-22.636h12.006c8.004 0 10.63-2.626 10.63-10.63v-50.65c0-18.633-8.004-30.639-26.638-30.639h-2.626c-16.008 0-33.266 14.632-33.266 40.02v93.294h-25.262V43.272h25.262v18.634c8.004-12.006 21.26-21.26 40.02-21.26 19.134 0 35.141 7.504 44.02 24.762 10.38-18.384 27.764-24.762 44.022-24.762 30.64 0 48.023 18.634 48.023 46.647v89.293h-25.513V92.671c0-18.634-8.003-30.64-26.637-30.64h-2.627c-16.007 0-33.266 14.632-33.266 40.02v21.135zm-192.967-82.54c-31.39 0-62.03 22.886-62.03 69.033 0 46.647 29.89 69.533 62.905 69.533 27.763 0 51.15-14.632 55.402-42.145H223.01c-2.627 14.132-15.133 20.76-28.514 20.76h-1.626c-16.508 0-36.017-13.631-37.518-44.02h93.67c2.501-48.274-19.634-73.161-57.027-73.161zm-35.142 53.276c4.752-23.762 20.26-32.016 33.891-32.016h2.626c14.883 0 28.514 8.504 30.89 32.016zM49.302 109.304L1.404 43.272h29.514L64.31 89.044l33.517-45.772h28.763l-47.898 65.532 49.274 67.657h-29.64l-34.64-47.648-34.893 47.648H.03zM594.94 43.272v18.634c-8.005-12.006-20.01-21.26-42.646-21.26-33.266 0-58.654 25.262-58.654 69.283s25.263 69.283 58.654 69.283c22.635 0 34.641-9.38 42.645-21.26v37.268h25.262V43.272zm-37.27 114.555h-2.626c-20.01 0-36.017-16.008-36.017-48.023s16.007-48.023 36.017-48.023h2.626c18.634 0 37.268 16.008 37.268 48.023s-18.634 48.023-37.268 48.023z" clip-rule="evenodd"/>
  </svg>
</header>
<nav id="project-miniatures" class="miniatures hidden">
<!--  <a class="miniature"-->
<!--     href="#xemantic"-->
<!--     data-flickity-bg-lazyload="projects/xemantic/xemantic-miniature.jpg">-->
<!--    <h2>Industria</h2>-->
<!--  </a>-->
<!--  <a class="miniature"-->
<!--     href="#xemantic"-->
<!--     data-flickity-bg-lazyload="projects/xemantic/xemantic-miniature.jpg">-->
<!--    <h2>Civilizational Habits</h2>-->
<!--  </a>-->
  <a class="miniature"
     href="#project404"
     data-flickity-bg-lazyload="404/404-miniature.jpg">
    <h2>404</h2>
  </a>
  <a class="miniature"
     href="#xemantic"
     data-flickity-bg-lazyload="projects/xemantic/xemantic-miniature.jpg">
    <h2>xemantic.com</h2>
  </a>
  <a class="miniature"
     href="#emotional-robots"
     data-flickity-bg-lazyload="projects/emotional-robots/emotional-robots-miniature.jpg">
    <h2>Emotional Robots</h2>
  </a>
  <a class="miniature"
     href="#we-are-the-robots"
     data-flickity-bg-lazyload="projects/we-are-the-robots/we-are-the-robots-miniature.jpg">
    <h2>we-are-the-robots</h2>
  </a>
  <a class="miniature"
     href="#dream-world"
     data-flickity-bg-lazyload="projects/dream-world/dream-world-miniature.jpg">
    <h2>Dream World</h2>
  </a>
  <a class="miniature"
     href="#angels-in-america"
     data-flickity-bg-lazyload="projects/angels-in-america/angels-in-america-miniature.jpg">
    <h2>Angels in America</h2>
  </a>
  <a class="miniature"
     href="#negentropy"
     data-flickity-bg-lazyload="projects/negentropy/negentropy-miniature.jpg">
    <h2>Negentropy</h2>
  </a>
  <a class="miniature"
     href="#generative-philosophy"
     data-flickity-bg-lazyload="projects/generative-philosophy/generative-philosophy-miniature.jpg">
    <h2>Generative Philosophy</h2>
  </a>
  <a class="miniature"
     href="#deconstruction-of-hitler-neural-synthesis-of-generative-wittgenstein"
     data-flickity-bg-lazyload="projects/deconstruction-of-hitler-neural-synthesis-of-generative-wittgenstein/deconstruction-of-hitler-neural-synthesis-of-generative-wittgenstein-miniature.jpg">
    <h2>Deconstruction of Hitler, neural synthesis of generative Wittgenstein</h2>
  </a>
  <a class="miniature"
     href="#the-last-flight-of-challenger"
     data-flickity-bg-lazyload="projects/the-last-flight-of-challenger/the-last-flight-of-challenger-miniature.jpg">
    <h2>The last flight of Challenger</h2>
  </a>
  <a class="miniature"
     href="#the-early-green-outburst"
     data-flickity-bg-lazyload="projects/the-early-green-outburst/the-early-green-outburst-miniature.jpg">
    <h2>The early green outburst</h2>
  </a>
  <a class="miniature"
     href="#music-of-the-eclipse"
     data-flickity-bg-lazyload="projects/music-of-the-eclipse/music-of-the-eclipse-miniature.jpg">
    <h2>Music of the eclipse</h2>
  </a>
</nav>
<section id="projects" class="hidden">
  <article id="project404">
    <div class="media">
      <img src="404/404-social-media-logo.jpg" loading="lazy" />
    </div>
    <div class="description">
      <h2>404</h2>
      <p>
        A collaborative interdisciplinary feedback loop between all the particular feedback
        loops of Zinnia Nomura, Takumi Motokawa and Kazik Pogoda.
      </p>
      <p>
        <a href="404/">project website</a>
      </p>
    </div>
  </article>
  <article id="xemantic">
    <div class="media">
      <iframe class="iframe" data-src="index.html" loading="lazy"></iframe>
      <div class="caption">
        Enjoy this recursive fractal. I <i class="fas fa-heart"></i> going meta. :)
      </div>
    </div>
    <div class="description">
      <h2>xemantic.com</h2>
      <p class="intro">
        This website was born, because I wanted to adequately present all my work, spanning
        across variety of disciplines and realized in a diverse media. I express myself with the
        code, but it's not something one can easily perceive. Thus here is the wrapping.
      </p>
      <p>
        I wanted to make it visually rich, using state of the art web technologies:
        WebGL2, CSS calculations and animations. Instead of using any existing responsive web design
        framework, I design everything from scratch, having certain experience in mind and actively
        shaping it. The initial page loads blazing fast, because everything is encoded in the base
        HTML with the conceptual layer of my generative mathematics, which creates the ultimate
        form of compression. The font is scaling linearly adjusting to any resolution.
        I added a shader, generating a slow synaesthetic background in real time, where the natural
        colors of the rainbow transform into movement. It is light enough to run on mobile devices.
        In terms of proportions, I applied golden ratio everywhere I could think of.
      </p>
      <p>
        The <em>xemantic.com</em> website is listed here, because it represents a significant
        project on it's own. As you can see I can also create websites and frontend apps.
        Maybe you need one? I can help build it or consult on techniques.
        I didn't intent to copy Netflix navigation, but the comparison seems inevitable.
        Maybe it's a seed of an art-streaming platform &mdash; a presentation form more suitable
        for the time of social distancing?
      </p>
    </div>
  </article>
  <article id="emotional-robots">
    <div class="media">
      <img src="projects/emotional-robots/shumi-frenzy-of-exultations.jpg" loading="lazy" />
      <div class="caption">
        It took this picture when my friend Shumi Szumacher, with whom I share the same
        mother tongue, quickly assembled a new costume for the robot out of a bubble wrap. I could
        not resist to pair it with
        <a href="https://en.wikipedia.org/wiki/Frenzy_of_Exultations">Frenzy of Exultations</a> by
        <a href="https://en.wikipedia.org/wiki/W%C5%82adys%C5%82aw_Podkowi%C5%84ski">Władysław Podkowiński</a>.
      </div>
    </div>
    <div class="description">
      <h2>Emotional Robots</h2>
      <p class="intro">
        Imagine a swarm of robots who are curious, anxious, cute, obnoxious. Behaving like if they
        were experiencing affectionate states driving their agency.
      </p>
      <p>
        I turned towards robotics during the time of pandemic, when the gig-economy collapsed, so
        did most of my other projects which live only with the audience perceiving them &mdash;
        <em>esse est percipi</em>. At least androids cannot be infected with bio-viruses.
        I am grateful that my friend <a href="https://jheer.com/">Jacqueline Heer</a>
        commissioned the first one of this breed of art-robots, to display her work with a mobile
        projection. We will evolve this new <em>genus</em> much further.
      </p>
      <p>
        I am building many of these machines currently, evoking diverse experiences due to
        their unique autonomy:
        insect-like movement among the crowd, while reciting machine poetry, offering gnostic
        encounters, and glowing with video-skin.
        I invite my friends to help me in shaping the experience.
        Check for updates soon. I opened the source of the whole software
        stack which emerged for this purpose as
        <a href="#we-are-the-robots"><nobr>we-are-the-robots</nobr></a> project and I am happy
        to help with your <q>emotional</q> machines.
      </p>
    </div>
  </article>
  <article id="we-are-the-robots">
    <div class="media">
      <img class="medium" src="projects/we-are-the-robots/we-are-the-robots-code-example.jpg" loading="lazy"/>
    </div>
    <div class="description">
      <h2>we-are-the-robots</h2>
      <p class="intro">
        Robotic software for artists &mdash; upcycling useful vacuum cleaners into useless
        (but maybe profound) experiences.
      </p>
      <p>
        Obviously the name refers to the iconic
        <a href="https://en.wikipedia.org/wiki/The_Robots"><em>Die Roboter</em></a> single
        by the legendary <a href="https://en.wikipedia.org/wiki/Kraftwerk">Kraftwerk</a>.
      </p>
      <p>
        The project is made out of building blocks, which can be easily assembled into new behavioral
        patterns. Although any type of robot might benefit from this framework, it is focused on
        the experience of people interacting with the machine. Check out the
        <a href="https://github.com/xemantic/we-are-the-robots"><i class="fab fa-github"></i> <nobr>we-are-the-robots</nobr> project on GitHub</a>.
        The experiences I am working on with my friends
        will pop up in the <a href="#emotional-robots">Emotional Robots</a> project.
      </p>
    </div>
  </article>
  <article id="dream-world">
    <div class="media">
      <div class="flickity">
        <div class="medium vimeo-video" data-video-id="400938448"></div>
        <img class="medium" src="projects/dream-world/dream-world-collective.jpg" loading="lazy" />
      </div>
    </div>
    <div class="description">
      <h2>Dream World</h2>
      <p class="intro">
        An immersive art experience which I helped to shape with media installations.
      </p>
      <p>
        There is something <a href="https://www.thefreedictionary.com/oneiric">oneiric</a>
        in my visuals. I am not surprised that they matched the vision behind
        <a href="https://dreamworld.space/">Dream World</a> project.
      </p>
      <p>
        At the end of 2019 an art collective was given a building &mdash; <q>soon to be demolished car
        repair shop</q>. In a very short time, with an extraordinary effort, the installation emerged.
        We had finished building it just 3 minutes before the first guests arrived. And since then
        the show had been running almost every day until the demolition.
      </p>
    </div>
  </article>
  <article id="angels-in-america">
    <div class="media">
      <div class="flickity">
        <div class="medium vimeo-video" data-video-id="437489981"></div>
        <div class="medium vimeo-video" data-video-id="340095745"></div>
        <div class="medium vimeo-video" data-video-id="342230851"></div>
        <img class="medium" src="projects/angels-in-america/angels-in-america-poster.jpg" loading="lazy" />
      </div>
    </div>
    <div class="description">
      <h2>Angels in America</h2>
      <p class="intro">
        Visuals for the Opera by <a href="">Péter Eötvös</a>, based on the play by
        <a href="https://en.wikipedia.org/wiki/Tony_Kushner">Tony Kushner</a>, staged at
        <a href="https://www.udk-berlin.de/universitaet/lehre-unter-den-bedingungen-des-digitalen/fakultaet-darstellende-kunst/unit-theater-der-universitaet-der-kuenste-berlin/">UNI.T</a>
        &mdash; the theater of <a href="https://www.udk-berlin.de/">Universität der Künste Berlin</a>
        (Berlin University of the Arts). See
        <a href="https://www.udk-berlin.de/universitaet/lehre-unter-den-bedingungen-des-digitalen/fakultaet-darstellende-kunst/unit-theater-der-universitaet-der-kuenste-berlin/produktionen/angels-in-america/">the official UdK website</a>.
      </p>
      <p>
        The screen, a giant white circle behind the stage, became my canvas to paint with light.
        My friend Iris Christidi,
        who designed the stage, saw my visuals rendering <q>wings</q> around human silhouette and she
        though it would be a fit for the narrative. I improved the experience to gently transform
        the outline of moving arms into feather, and then feather into spacious clouds.
        Working behind the stage &mdash; it was the first experience of this kind in my life,
        and I loved it. There is a magic to it which gets addictive &mdash; to consciously design
        and prepare the show for the audience.
      </p>
      <p>
        I use to name my code according to the ontologies of modern capitalism:
      </p>
      <blockquote>
        Customer.java<br/>
        Account.java<br/>
        Transfer.java<br/>
        TransactionProcessor.java
      </blockquote>
      <p>
        But this time I could write my own code poetry according to
        the libretto:
      </p>
      <blockquote>
        Scene02OzoneLayer.kt<br/>
        Scene06And14Ethel.kt<br/>
        Scene11And12AngelicSilhouette.kt<br/>
        Scene12AngelicEjaculate.kt<br/>
        CircularProjectionMapper.glsl<br/>
        OzoneMixer.glsl<br/>
        EjaculateMixer.glsl
      </blockquote>
      <p>
        The poetics of code and the politics of code. Written for the narrative which is political
        to the bone, and still surprisingly actual, especially in my home country, where LGBTQ+
        community became the imaginary enemy so much needed by Polish right-wing politicians.
      </p>
      <p>
        I've also learned a lot about technical side of installations on this scale. Projections
        become very pale when other stage lights are involved. It's more important to operate
        on contrast than on color. We couldn't afford real time visuals in this show, but
        my friend and collaborator <a href="https://cidvsx.com/">Rodrigo CID</a> built a VJ console
        prepared for this libretto.
      </p>
      <p>
        I wrote about the process, and all the new and unexpected feelings I experienced while
        working on this project, in the series of 2 articles:
        <a href="https://medium.com/@kazikpogoda/angels-in-america-visuals-for-the-opera-eea7807c7555?source=friends_link&sk=02a00686d0408c9dc587c2f9fbbb6eed">Angels in America &mdash; visuals for the opera</a>
        and <a href="https://medium.com/@kazikpogoda/ethel-2c013df74a5b?source=friends_link&sk=a2b7f0b92b94a8565d5d30d0543e1548">Ethel</a>
      </p>
    </div>
  </article>
  <article id="negentropy">
    <div class="media">
      <img src="projects/negentropy/Negentropy-Kazik_Pogoda-Generative-2020.jpg" loading="lazy" />
    </div>
    <div class="description">
      <h2>Negentropy</h2>
      <p class="intro">
        I am still far away visually from where I want to be. But this
        still frame from a sound-reactive visual is my own favorite so far (yes, it's a real time
        experience!). And when people started
        sharing with me the emotions they experience when perceiving it, it made me believe
        that I am on the right path with my <q>emotional generative art</q>.
      </p>
      <blockquote>
        This is what I hope my afterlife looks like.
      </blockquote>
      <blockquote>
        it’s captivating in ways that I can’t convey with words... it’s beyond words...
      </blockquote>
      <blockquote>
        Enveloping, silky smooth, light, but enough dark to communicate that we have known pain
        and keep a part of ourself that will always remember.
      </blockquote>
      <blockquote>
        feels like silk
      </blockquote>
      <blockquote>
        This image is stunning. I feel hopeful when I look at it.
      </blockquote>
      <blockquote>
        I feel this is the closest i'll get to seeing colours the human eye can't see. This is what
        bee's must experience when they're looking at to what to us is just an ordinary yellow
        flower. It also reminds me of the reflective inside of abalone shells and
        I can imagine it shimmering when turned in the sunlight.
      </blockquote>
      <blockquote>
        This is what the sky would look like for a being that lived in an opal.
      </blockquote>
    </div>
  </article>
  <article id="generative-philosophy">
    <div class="media">
      <img src="projects/negentropy/Negentropy-Kazik_Pogoda-Generative-2020.jpg" loading="lazy"/>
    </div>
    <div class="description">
      <h2>Generative philosophy</h2>
      <p class="intro">
        Can machine synthesize a meaning for us?
      </p>
      <p>
        I want to transform my research into experience. It will be obviously about philosophy,
        it's status and relevance in the modern era. About logic, ethics, aesthetics, transcendence,
        genius, unfulfilled ambitions, <em>statolatry</em> - cult of the national state, and the
        reemergence of right-wing ideologies. I wrote an article with covers some details of the
        narrative: <a href="#deconstruction-of-hitler-neural-synthesis-of-generative-wittgenstein">
        Deconstruction of Hitler, neural synthesis of generative Wittgenstein</a>
      </p>
    </div>
  </article>
  <article id="deconstruction-of-hitler-neural-synthesis-of-generative-wittgenstein">
    <div class="media">
      <img src="projects/deconstruction-of-hitler-neural-synthesis-of-generative-wittgenstein/Sophia_Crespo-synthetic_emotionality_9876-2018.jpg" loading="lazy"/>
      <div class="caption">
        <a href="https://sofiacrespo.com/">Sofia Crespo</a>, {synthetic_emotionality_9876}, 2018<br/>
        My favorite image generated with neural networks. The print hangs on my wall in a golden baroque frame.
      </div>
    </div>
    <div class="description">
      <h2>Deconstruction of Hitler, neural synthesis of generative Wittgenstein</h2>
      <p class="intro">
        An article which I wrote when AI-generated philosophy surprised me with
        significance of it's products, shining a new light on meta-theories of our
        culture.
      </p>
      <p>
        I want to transform my research into experience. It will be obviously about philosophy,
        it's status and relevance in the modern era. About logic, ethics, aesthetics, transcendence,
        genius, how unfulfilled artistic ambitions can lead to the mass genocide, <em>statolatry</em> - cult of the national state, and the
        reemergence of right-wing ideologies. I wrote an article with covers some details of the
        narrative:
        <a href="https://medium.com/@kazikpogoda/deconstruction-of-hitler-neural-synthesis-of-generative-wittgenstein-3682484a7669?source=friends_link&sk=369f1512ec89948e346ce0f814784118">
        Deconstruction of Hitler, neural synthesis of generative Wittgenstein</a>
      </p>
    </div>
  </article>
  <article id="the-last-flight-of-challenger">
    <div class="media">
      <img src="projects/the-last-flight-of-challenger/the-last-flight-of-challenger-explosion.jpg" loading="lazy"/>
    </div>
    <div class="description">
      <h2>The last flight of Challenger</h2>
      <p class="intro">
        I think about myself as a feminist, and it's a political statement. I am willing to
        discover and constantly expose the inner mechanics of the patriarchal system, even if it is
        concealed by the layers of cultural conventions and civilizational habits. The <q>modernized
        patriarchy</q> is becoming transparent, but it makes it potentially even more oppressive
        and deadly.
      </p>
      <blockquote>
        So here it is, the quintessence of the phallic culture, propelled by the unbelievable
        amount of energy, to create a tiny new local homeostasis out of chaos. In my mother
        tongue the <q>entropy</q> is feminine, and she says: <q>fuck yourself</q>.
      </blockquote>
      <p>
        It's a quote from the article:
        <a href="https://medium.com/@kazikpogoda/the-last-flight-of-challenger-56d4abfc71db?source=friends_link&sk=0bdf89814c5001887b6454801bf901ab"><q>The last flight of Challenger</q></a>
        published on Medium.
      </p>
    </div>
  </article>
  <article id="the-early-green-outburst">
<!--    <div class="media">-->
<!--      -->
<!--    </div>-->
    <div class="media">
      <div class="medium vimeo-video" data-video-id="361821257"></div>
    </div>
    <div class="description">
      <h2>The early green outburst</h2>
      <p class="intro">
        Experimental generative impressionist video shaped by the music of
        <a href="https://floatingspectrum.com/">Floating Spectrum</a>.
      </p>
      <p>
        The <em>Floating Spectrum</em> is a moniker of my friend Mei-Fang Liau. What you see here
        is not a music video.
        It's rather an impression in the form of sound-reactive visual inspired by her music, and
        adjusted to her music. A <q>generative impressionism</q> &mdash; I don't know if such a
        genre exists, but this is how I feel when working with the music. And surprisingly it became
        <a href="https://vimeo.com/361821257">the most popular video on my vimeo</a>.
      </p>
      <p>
        Mei-Fang is coding her own custom generative music engines and software synthesizers.
        Her frequencies and oscillations are so different and intriguing, that I couldn't resist
        the urge to meditate with visual coefficients. The oscillation is constant, while the
        intensity of the movement and color depends on the intensity of sound.
      </p>
    </div>
  </article>
  <article id="music-of-the-eclipse">
    <div class="media">
      <img src="projects/music-of-the-eclipse/music-of-the-eclipse.jpg" loading="lazy"/>
    </div>
    <div class="description">
      <h2>Music of the eclipse</h2>
      <p class="intro">
        Working on generative visuals brings associations, with the past, with the present,
        with many phenomena perceived before. The outcome of mathematical formulas is abstract in
        own form. The <em>abstract</em> signifies nothing &mdash; manifests this perfect detachment
        from any context which would anchor to the prior experience. But maybe because of this
        it has the power to <q>show</q> what cannot be expressed in the medium of language.
      </p>
      <p>
        Reading
        <a href="https://medium.com/@kazikpogoda/music-of-the-eclipse-e444670dfd0f?source=friends_link&sk=3752a6c452dafa698382120f9d3a7045"><q>Music of the eclipse</q></a>
        literally will not answer what I meant, but maybe reading it will make you feel it?
      </p>
      <p>
        Other articles:
      </p>
      <ul>
        <li><a href="https://kazikpogoda.medium.com/is-there-anything-more-surreal-than-reality-7e76fdd74a5d?source=friends_link&sk=f5906fb29fbc74a66d1c93c47dbb569b">Is there anything more surreal than reality?</a></li>
      </ul>
    </div>
  </article>
</section>
<section id="social-media" class="shadow">
  <a href="https://www.instagram.com/xmorisilx/" title="Instagram"><i class="fab fa-instagram" aria-hidden="true"></i></a>
  <a href="https://twitter.com/KazikPogoda" title="Twitter"><i class="fab fa-twitter" aria-hidden="true"></i></a>
  <a href="https://vimeo.com/kazikpogoda" title="Vimeo"><i class="fab fa-vimeo" aria-hidden="true"></i></a>
  <a href="https://www.youtube.com/channel/UCLWGRPqrPBS7CDuaPxODmRQ" title="YouTube channel"><i class="fab fa-youtube" aria-hidden="true"></i></a>
  <a href="https://medium.com/@kazikpogoda" title="Medium articles"><i class="fab fa-medium" aria-hidden="true"></i></a>
  <a href="https://github.com/xemantic" title="xemantic GitHub"><i class="fab fa-github"></i></a>
  <a href="https://github.com/morisil" title="personal GitHub"><i class="fab fa-github-alt"></i></a>
  <a href="https://www.linkedin.com/in/kpogoda/" title="LinkedIn"><i class="fab fa-linkedin" aria-hidden="true"></i></a>
  <a href="https://www.facebook.com/kazimierz.pogoda" title="facebook"><i class="fab fa-facebook" aria-hidden="true"></i></a>
</section>
<section id="me" class="hidden content-container">
  <img src="images/xemantic-collective.jpg"
       alt="Xemantic collective after 404 show staged at Monopol, Berlin, 2022"
       class="left width-shorter"
       loading="lazy" />
  <h2>Xemantic Manifesto</h2>
  <h3>A Collective of Applied Philosophy</h3>
  <p>
    We recognize that the relationship between humans and our digital machines evolved into a form of <q>symbiosis</q>.
    Exponential growth of technical complexity results in an unprecedented amount of information processors. The
    quantity emerges a new quality of cognition &mdash; new forms of culture. In all these processes we view code as a medium,
    analogous to the role genetic code plays in biology. Most of the code written today follows the demand and supply
    chains of the market economy. We advocate for the code manifesting our humanistic values instead of anticipated
    profit. We code with ethical and aesthetic motivation &mdash; for a better society and for arts. We embrace technological
    progress, while remaining critical towards the outcomes. Therefore we help effective organizations to be even more
    efficient in their use of technology, we connect generative practices with performative practices, and we engage in
    various forms of activism and artivism.
  </p>
  <p>
    Signed by:
  </p>
  <dl>
    <dt>Alan Pogoda</dt><dd>digital native storyteller (Gen Alpha)</dd>
    <dt>Julie Amouzegar Kim</dt><dd>visual artist and composer (Gen Z)</dd>
    <dt>Julia Thomas</dt>
    <dd>psychologist, philosopher, machine learning specialist at krisenchat.de (crisis counseling for Gen Z)</dd>
    <dt>Zinnia Nomura</dt><dd>director, dancer, choreographer</dd>
    <dt>Keith Lim</dt><dd>director of immersive theaters, dancer, programmer</dd>
    <dt>Takumi Motokawa</dt><dd>generative composer</dd>
    <dt>Alex Cuthbertson</dt><dd>co-founder of Dream World immersive theater, flow artist, builder</dd>
    <dt>Monika <q>pacyfka</q> Tichy</dt><dd> the founder of Lambda Poland Foundation (LGBTQ+ rights in Poland)</dd>
    <dt>Dan Gorelick</dt><dd>sound artist, live-coder, organizer</dd>
    <dt>Omii Chen</dt><dd>visual artist, graphic novelist, pornographist</dd>
    <dt>Kazik Pogoda</dt><dd>generative visualist, philosopher, the mother of Xemantic</dd>
  </dl>
  <img src="images/me/kazik-pogoda-at-coart-timisoara.jpg"
       alt="Kazik Pogoda at co(art) Festival, Timișoara 2019"
       class="left width-shorter"
       loading="lazy" />
  <p>
    My name is Kazik Pogoda and
    <img src="logo/xemantic-logo.svg" class="logo-in-text" alt="xemantic logo" loading="lazy"/>
    is a label I have been using as an umbrella for my projects. The Xemantic collective
    was born out of numerous collaborations with people sharing the same values.
    We usually meet and collaborate in Berlin, at <a href="https://prachtsaal.berlin/">Prachtsaal Studio</a>, a beautiful space
    in the middle of Neukölln district.
  </p>
  <p>
    I am working as a software architect for NGOs like <a href="https://krisenchat.de/">Krisenchat</a>, and as a
    <em><a href="https://en.wikipedia.org/wiki/Creative_technology">creative technologist</a></em> &mdash;
    a fancy phrase to say that instead
    of using Adobe products I write my own software. Achieving the aesthetics I desire requires
    writing a custom code. The practice is called <em>creative coding</em>, and the outcome is
    called <em><a href="https://en.wikipedia.org/wiki/Generative_art">generative art</a></em>
    or <em><a href="https://en.wikipedia.org/wiki/Generative_design">generative design</a></em>.
    I feel neither like an artist nor like a designer. I majored in philosophy and
    what I create is rather reflecting my philosophical believes on the evolution extending
    far beyond the context of biology, also to human culture, where suddenly the new fabric of
    <q>reality</q> is woven out of our symbiosis with the machines.
  </p>
  <p>
    I enjoy speaking their languages and I understand them well. But my love stays with humans.
    I love to collaborate, because it always brings additional humanistic narrative and
    dimension to my own work, when it is becoming part of some bigger story to tell.
    Feel free to <a class="email"><i class="fas fa-envelope-square"></i> contact me</a>.
  </p>
  <img class="right width-shorter"
       src="images/me/kazik-pogoda-synthesizing-videos.jpg"
       alt="Kazik Pogoda synthesizing videos, 2019"
       loading="lazy" />
  <p>
    I started working with creative technologies very recently, even though it is something
    I was fascinated with as a teenager back in Poland, in the time when my home country
    was transforming from the communist to the capitalist economy.
    I've been working for years with software, as chief architect, lead developer
    and mentor of other
    programmers, in diverse international teams. I've produced software used by millions of
    human and non-human agents. You can find my full professional curriculum on
    <a href="https://www.linkedin.com/in/kpogoda/"><i class="fab fa-linkedin"></i> LinkedIn</a>.
  </p>
  <p>
    But now I want to use code for different purposes. I want to evoke affectionate states with
    the use of machines &mdash; <em>emotional generative art</em>. Make you feel something when you
    perceive a product of an algorithm. Either thanks to purely aesthetic and synaesthetic
    experience, or thanks to the conceptual relevance, when the narrative accurately meditates
    on our post-human condition.
  </p>
  <p>
    A glimpse of my recent work you can find on
    <a href="https://www.instagram.com/xmorisilx/"><i class="fab fa-instagram"></i> Instagram</a>
    <a href="https://twitter.com/KazikPogoda"><i class="fab fa-twitter"></i> Twitter</a>
    and <a href="https://www.facebook.com/kazimierz.pogoda"><i class="fab fa-facebook"></i> Facebook</a>.
    . They are good platforms for sharing static visuals, but I want to deliver an
    experience and it's not easy to convey without an immersive interactive installation. I guess
    <a href="https://vimeo.com/kazikpogoda"><i class="fab fa-vimeo"></i> Vimeo</a>
    and my
    <a href="https://www.youtube.com/channel/UCLWGRPqrPBS7CDuaPxODmRQ"><i class="fab fa-youtube"></i> YouTube channel</a>
    provide a better feeling of it. I also publish there more experimental generative videos.
  </p>
  <p>
    When it comes to <em>meta</em> and the narrative behind my work,
    I also write on <a href="https://medium.com/@kazikpogoda"><i class="fab fa-medium"></i> Medium</a>
    Follow me if you wish, wherever you wish, or write me an email <i class="fas fa-envelope-square"></i>:
  </p>
  <p><a class="email"><span class="email"></span></a></p>
  <p>
    And last, but not least, the code itself. I open the source of my tools.
    Check out <a href="https://github.com/xemantic"><i class="fab fa-github"></i> xemantic GitHub</a>
    for the list of official projects and my
    <a href="https://github.com/morisil"><i class="fab fa-github-alt"></i> personal GitHub</a> with
    smaller experiments.
  </p>
  <p>
    Note: Here is <a href="old/index.html">the previous version of xemantic.com</a>, just in case you
    want to study the evolution of this website.
  </p>
</section>
<footer class="shadow hidden">
  <div>
    <p>
      Copyright &copy; 2023 Kazimierz Pogoda / xemantic.com All Rights Reserved
    </p>
    <p>
      <img src="logo/xemantic-logo.svg"
           class="logo-in-text"
           alt="xemantic logo" loading="lazy"/>
      logo designed with <i class="fas fa-heart"></i> by <a href="https://ivanskoro.com/">Ivan Škoro</a>.
    </p>
  </div>
</footer>
<canvas id="shader-background"></canvas>
</body>
</html>
